{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset import get_datasets\n",
    "from logistic import softmax, cross_entropy, accuracy\n",
    "    \n",
    "    \n",
    "def sgd(params, grads, lr, bs):\n",
    "    \"\"\"\n",
    "    stochastic gradient descent implementation\n",
    "    args:\n",
    "    - params [list[tensor]]: model params\n",
    "    - grad [list[tensor]]: param gradient\n",
    "    - lr [float]: learning rate\n",
    "    - bs [int]: batch_size\n",
    "    \"\"\"\n",
    "    for param, grad in zip(params, grads):\n",
    "        param.assign_sub(lr * grad / bs)\n",
    "\n",
    "\n",
    "def training_loop(lr):\n",
    "    \"\"\"\n",
    "    training loop\n",
    "    args:\n",
    "    - lr [float]: learning rate\n",
    "    returns:\n",
    "    - mean_acc [tensor]: training accuracy\n",
    "    - mean_loss [tensor]: training loss\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for X, Y in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            X = X / 255.0\n",
    "            y_hat = model(X)\n",
    "            # calculate loss\n",
    "            one_hot = tf.one_hot(Y, 43)\n",
    "            loss = cross_entropy(y_hat, one_hot)\n",
    "            losses.append(tf.math.reduce_mean(loss))\n",
    "\n",
    "            grads = tape.gradient(loss, [W, b])\n",
    "            sgd([W, b], grads, lr, X.shape[0]) \n",
    "\n",
    "            acc = accuracy(y_hat, Y)\n",
    "            accuracies.append(acc)\n",
    "    mean_acc = tf.math.reduce_mean(tf.concat(accuracies, axis=0))\n",
    "    mean_loss = tf.math.reduce_mean(losses)\n",
    "    return mean_loss, mean_acc\n",
    "\n",
    "def model(X):\n",
    "    \"\"\"\n",
    "    logistic regression model\n",
    "    \"\"\"\n",
    "    flatten_X = tf.reshape(X, (-1, W.shape[0]))\n",
    "    return softmax(tf.matmul(flatten_X, W) + b)\n",
    "\n",
    "    \n",
    "def validation_loop(val_dataset, model):\n",
    "    \"\"\"\n",
    "    loop through the validation dataset\n",
    "    \"\"\"\n",
    "    accuracies = []\n",
    "    for X, Y in val_dataset:\n",
    "        X = X / 255.0\n",
    "        y_hat = model(X)\n",
    "        acc = accuracy(y_hat, Y)\n",
    "        accuracies.append(acc)\n",
    "    mean_acc = tf.math.reduce_mean(tf.concat(accuracies, axis=0))\n",
    "    return mean_acc\n",
    "\n",
    "\n",
    "def get_module_logger(mod_name):\n",
    "    logger = logging.getLogger(mod_name)\n",
    "    handler = logging.StreamHandler()\n",
    "    formatter = logging.Formatter('%(asctime)s %(levelname)-8s %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    return logger\n",
    "\n",
    "\n",
    "if __name__  == '__main__':\n",
    "    logger = get_module_logger(__name__)\n",
    "    parser = argparse.ArgumentParser(description='Download and process tf files')\n",
    "    parser.add_argument('--imdir', required=True, type=str,\n",
    "                        help='data directory')\n",
    "    parser.add_argument('--epochs', default=10, type=int,\n",
    "                        help='Number of epochs')\n",
    "    args = parser.parse_args()    \n",
    "\n",
    "    logger.info(f'Training for {args.epochs} epochs using {args.imdir} data')\n",
    "    # get the datasets\n",
    "    train_dataset, val_dataset = get_datasets(args.imdir)\n",
    "\n",
    "    # set the variables\n",
    "    num_inputs = 1024*3\n",
    "    num_outputs = 43\n",
    "    W = tf.Variable(tf.random.normal(shape=(num_inputs, num_outputs),\n",
    "                                    mean=0, stddev=0.01))\n",
    "    b = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    lr = 0.1\n",
    "    # training! \n",
    "    for epoch in range(args.epochs):\n",
    "        logger.info(f'Epoch {epoch}')\n",
    "        loss, acc = training_loop(lr)\n",
    "        logger.info(f'Mean training loss: {loss:1f}, mean training accuracy {acc:1f}')\n",
    "        val_acc = validation_loop(val_dataset, model)\n",
    "        logger.info(f'Mean validation accuracy {val_acc:1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
