{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'waymo-od'...\n",
      "remote: Enumerating objects: 1718, done.\u001b[K\n",
      "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
      "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
      "remote: Total 1718 (delta 69), reused 133 (delta 67), pack-reused 1575\u001b[K\n",
      "Receiving objects: 100% (1718/1718), 42.15 MiB | 1.93 MiB/s, done.\n",
      "Resolving deltas: 100% (1088/1088), done.\n",
      "* \u001b[32mmaster\u001b[m\n",
      "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/master\n",
      "  \u001b[31mremotes/origin/master\u001b[m\n",
      "  \u001b[31mremotes/origin/om2\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.0\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.0-tf1.15\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.0-tf2.0\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.2\u001b[m\n",
      "  \u001b[31mremotes/origin/r1.3\u001b[m\n",
      "Note: checking out 'remotes/origin/master'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n",
      "HEAD is now at 17f0700 Merged commit includes the following changes: 449089867  by Waymo Research:\n",
      "Requirement already satisfied: pip in /Users/aravindagayan/anaconda3/lib/python3.7/site-packages (22.2.2)\n",
      "Collecting pip\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.2.2\n",
      "    Uninstalling pip-22.2.2:\n",
      "      Successfully uninstalled pip-22.2.2\n",
      "Successfully installed pip-22.3.1\n"
     ]
    }
   ],
   "source": [
    "!rm -rf waymo-od > /dev/null\n",
    "!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
    "!cd waymo-od && git branch -a\n",
    "!cd waymo-od && git checkout remotes/origin/master\n",
    "!pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'waymo_open_dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-26c3db7a520c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwaymo_open_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdataset_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopen_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint64_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint64_list_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'waymo_open_dataset'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from PIL import Image\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "\n",
    "from utils import parse_frame, int64_feature, int64_list_feature, bytes_feature\n",
    "from utils import bytes_list_feature, float_list_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "from PIL import Image\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "\n",
    "from utils import parse_frame, int64_feature, int64_list_feature, bytes_feature\n",
    "from utils import bytes_list_feature, float_list_feature\n",
    "\n",
    "\n",
    "def create_tf_example(filename, encoded_jpeg, annotations):\n",
    "    \"\"\"\n",
    "    convert to tensorflow object detection API format\n",
    "    args:\n",
    "    - filename [str]: name of the image\n",
    "    - encoded_jpeg [bytes-likes]: encoded image\n",
    "    - annotations [list]: bboxes and classes\n",
    "    returns:\n",
    "    - tf_example [tf.Example]\n",
    "    \"\"\"\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpeg)\n",
    "    image = Image.open(encoded_jpg_io)\n",
    "    width, height = image.size\n",
    "    \n",
    "    mapping = {1: 'vehicle', 2: 'pedestrian', 4: 'cyclist'}\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "    filename = filename.encode('utf8')\n",
    "    \n",
    "    for ann in annotations:\n",
    "        xmin, ymin = ann.box.center_x - 0.5 * ann.box.length, ann.box.center_y - 0.5 * ann.box.width\n",
    "        xmax, ymax = ann.box.center_x + 0.5 * ann.box.length, ann.box.center_y + 0.5 * ann.box.width\n",
    "        xmins.append(xmin / width)\n",
    "        xmaxs.append(xmax / width)\n",
    "        ymins.append(ymin / height)\n",
    "        ymaxs.append(ymax / height)    \n",
    "        classes.append(ann.type)\n",
    "        classes_text.append(mapping[ann.type].encode('utf8'))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': int64_feature(height),\n",
    "        'image/width': int64_feature(width),\n",
    "        'image/filename': bytes_feature(filename),\n",
    "        'image/source_id': bytes_feature(filename),\n",
    "        'image/encoded': bytes_feature(encoded_jpeg),\n",
    "        'image/format': bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "        'image/object/class/text': bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example\n",
    "\n",
    "\n",
    "def process_tfr(path):\n",
    "    \"\"\"\n",
    "    process a waymo tf record into a tf api tf record\n",
    "    \"\"\"\n",
    "    # create processed data dir\n",
    "    file_name = os.path.basename(path)\n",
    "\n",
    "    logging.info(f'Processing {path}')\n",
    "    writer = tf.python_io.TFRecordWriter(f'../output/{file_name}')\n",
    "    dataset = tf.data.TFRecordDataset(path, compression_type='')\n",
    "    \n",
    "    for idx, data in enumerate(dataset):\n",
    "        frame = open_dataset.Frame()\n",
    "        frame.ParseFromString(bytearray(data.numpy()))\n",
    "        encoded_jpeg, annotations = parse_frame(frame)\n",
    "        filename = file_name.replace('.tfrecord', f'_{idx}.tfrecord')\n",
    "        tf_example = create_tf_example(filename, encoded_jpeg, annotations)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-p', '--path', required=True, type=str,\n",
    "                        help='Waymo Open dataset tf record')\n",
    "    args = parser.parse_args()  \n",
    "    process_tfr(args.path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
