{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import schedules\n",
    "from utils import get_datasets, get_module_logger, display_metrics, \\\n",
    "    create_network, LrLogger\n",
    "\n",
    "\n",
    "def exponential_decay(model, callbacks, lr=0.001):\n",
    "    \"\"\" use exponential decay \"\"\"\n",
    "    # add decay\n",
    "    scheduler = schedules.ExponentialDecay(lr, decay_steps=100, decay_rate=0.95)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=scheduler)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model, callbacks\n",
    "\n",
    "\n",
    "def step_decay(model, callbacks, lr=0.001):\n",
    "    \"\"\" create custom decay using learning rate scheduler \"\"\"\n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch % 10 == 0 and epoch > 0:\n",
    "            lr /= 2\n",
    "        return lr \n",
    "    callbacks.append(tf.keras.callbacks.LearningRateScheduler(scheduler))\n",
    "\n",
    "    # create optimizer\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model, callbacks\n",
    "\n",
    "\n",
    "if __name__  == '__main__':\n",
    "    logger = get_module_logger(__name__)\n",
    "    parser = argparse.ArgumentParser(description='Download and process tf files')\n",
    "    parser.add_argument('-d', '--imdir', required=True, type=str,\n",
    "                        help='data directory')\n",
    "    parser.add_argument('-e', '--epochs', default=10, type=int,\n",
    "                        help='Number of epochs')\n",
    "    args = parser.parse_args()    \n",
    "\n",
    "    logger.info(f'Training for {args.epochs} epochs using {args.imdir} data')\n",
    "    # get the datasets\n",
    "    train_dataset, val_dataset = get_datasets(args.imdir)\n",
    "    logger = LrLogger()\n",
    "    callbacks = [logger]\n",
    "\n",
    "    model = create_network()\n",
    "\n",
    "    # model, callbacks = exponential_decay(model, callbacks)\n",
    "    model, callbacks = step_decay(model, callbacks)\n",
    "\n",
    "    history = model.fit(x=train_dataset, \n",
    "                        epochs=args.epochs, \n",
    "                        validation_data=val_dataset,\n",
    "                        callbacks=callbacks)\n",
    "    display_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
